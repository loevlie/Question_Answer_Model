{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c54a6a3-513b-45c3-989d-2c83d5355ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Utils import get_features\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from testingHelpers import NBcount,questionHasAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819c68ee-633b-4583-aa64-3d6b827bf236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('train-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202130d3-c96a-44f1-afea-4a8dc14ffb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_title(df,title_index):\n",
    "    \"\"\"Function to parse the SQUAD data structure for one article and return the full text, Questions and Answers.\n",
    "\n",
    "    Args:\n",
    "        df (dict): SQUAD data set structure\n",
    "        title_index (int): Index number for the article you would like to parse\n",
    "\n",
    "    Returns:\n",
    "        text (str): The full text of the article (paragraphs are separated by \\n)\n",
    "        Questions (list): A list of all of the questions (marked as possible)\n",
    "        Answers (list):  A list of all the answers corresponding to the Question list \n",
    "    \"\"\"\n",
    "\n",
    "    text = '\\n'.join([df['data'][title_index]['paragraphs'][i]['context'] for i in range(len(df['data'][title_index]['paragraphs']))])\n",
    "\n",
    "    Questions = []\n",
    "    Answers = []\n",
    "\n",
    "    for i in range(len(df['data'][title_index]['paragraphs'])):\n",
    "        for j in range(len(df['data'][title_index]['paragraphs'][i]['qas'])):\n",
    "            if df['data'][title_index]['paragraphs'][i]['qas'][j]['is_impossible'] == True:\n",
    "                continue\n",
    "            else:\n",
    "                Questions.append(df['data'][title_index]['paragraphs'][i]['qas'][j]['question'])\n",
    "                Answers.append([x['text'] for x in df['data'][title_index]['paragraphs'][i]['qas'][j]['answers']])\n",
    "    \n",
    "    return text, Questions, Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549551e7-2a5d-4deb-844d-dd40c469f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import spacy\n",
    "import QAfeatures\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def random_index(n, end, start = 0):\n",
    "    return list(range(start, n)) + list(range(n+1, end))\n",
    "\n",
    "def filter_questions(vecs,Answers,max_len=30):\n",
    "    \"\"\"First figure out if the answer was found in the feature vectors.  Next find and return the answer feature vector and a randomly selected incorrect answer feature vector.\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        vecs (list): list of n feature vectors (from n sentences choosen previously)\n",
    "        Answers (list): list of answers given by SQUAD\n",
    "\n",
    "    Returns:\n",
    "        found_answer (bool): Was the answer found or not?\n",
    "        correct_feature_vector (array): Feaure vector of the correct answer\n",
    "        incorrect_feature_vector (array): Feature vector of the incorrect answer\n",
    "    \"\"\"\n",
    "\n",
    "    # Did we find the correct answer?\n",
    "    feat_len = len(list(vecs.values())[0])\n",
    "    PAD = np.ones(feat_len)*-1\n",
    "    check = []\n",
    "    # for vec in vecs:\n",
    "    check.append(any(item in Answers for item in [str(i) for i in vecs.keys()]))\n",
    "    \n",
    "    feature_vectors = []\n",
    "    candidate_list = []\n",
    "    if any(check):\n",
    "        break_out_flag = False\n",
    "        # for vec in vecs:\n",
    "        feature_vectors.extend(list(vecs.values()))\n",
    "        candidate_list.extend([str(i) for i in list(vecs.keys())])\n",
    "        for Answer in set(Answers):\n",
    "            #vec_list = [str(i) for i in vec.keys()]\n",
    "            if Answer in candidate_list:\n",
    "                correct_index = candidate_list.index(Answer)\n",
    "                # print(feature_vectors)\n",
    "                # print(feature_vectors[correct_index])\n",
    "                # print(feature_vectors.count(feature_vectors[correct_index]))\n",
    "                count = 0\n",
    "                for i in feature_vectors:\n",
    "                    if all(i==list(feature_vectors[correct_index])):\n",
    "                        count+=1\n",
    "                \n",
    "                if count > 1: # This would mean there is at least one more feature vector equal to the correct one that is not correct \n",
    "                    feature_vectors = np.array([])\n",
    "                    output_vector = np.array([])\n",
    "                    found_answer = False\n",
    "                    break\n",
    "                else:\n",
    "                    if len(feature_vectors) < max_len: # We must pad!\n",
    "                        padding_array = [PAD for i in range(max_len-len(feature_vectors))]\n",
    "                        feature_vectors.extend(padding_array)\n",
    "                    \n",
    "                    output_vector = np.zeros(len(feature_vectors))\n",
    "                    output_vector[correct_index] = 1 # should still be the same index right?\n",
    "\n",
    "                    indices = np.arange(max_len)\n",
    "\n",
    "                    np.random.shuffle(indices)\n",
    "                    feature_vectors = np.array(feature_vectors)[indices]\n",
    "                    output_vector = np.array(output_vector)[indices]\n",
    "                    break_out_flag = True\n",
    "                    found_answer = True\n",
    "                    break\n",
    "            # if break_out_flag:\n",
    "            #     break\n",
    "    else:\n",
    "        feature_vectors = np.array([])\n",
    "        output_vector = np.array([])\n",
    "        found_answer = False\n",
    "\n",
    "\n",
    "    return found_answer, feature_vectors, output_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset(df,rel_sentences=3):\n",
    "    ######## THIS IS THE SECTION THAT TAKES FOREVER ##########\n",
    "    feature_vec = []\n",
    "    output_vec = []\n",
    "    error_answer = []\n",
    "    error_question = []\n",
    "    error_context = []\n",
    "    # Qtype = []\n",
    "    # Atype = []\n",
    "\n",
    "    for j in tqdm(range(len(df['data']))):\n",
    "        # if j == len(df['data'])-1:\n",
    "        #     return Qtype,Atype\n",
    "        #     break\n",
    "        #print(len(feature_vec))\n",
    "        #text, Questions, Answers = parse_title(df,j)\n",
    "        for P in df['data'][j]['paragraphs']:\n",
    "            for i, QA in enumerate(P['qas']):\n",
    "                if QA['is_impossible']:\n",
    "                    continue\n",
    "                \n",
    "                try: \n",
    "                    QS = QAfeatures.QuestionSense(QA['question'])\n",
    "                except:\n",
    "                    continue\n",
    "                try: # TODO \n",
    "                    vecs = get_features(text=nlp(P['context']),QS=QS,num_rel_sentences=rel_sentences)\n",
    "                except:\n",
    "                    #message.append(att)\n",
    "                    #error_question.append(QA['question'])\n",
    "                    continue\n",
    "                    \n",
    "                found = questionHasAnswer([x['text'] for x in QA['answers']],P['context'])\n",
    "                if found==False:\n",
    "                    #print(found)\n",
    "                    error_question.append(QA['question'])\n",
    "                    error_answer.append([x['text'] for x in QA['answers']][0])\n",
    "                    error_context.append(P['context'])\n",
    "  \n",
    "                \n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(feature_vec, output_vec, test_size=0.20, random_state=42)\n",
    "    return error_question,error_answer,error_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746b73d-6c8b-4165-9c3d-a88cf818306c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe1943fbb984878a82b3a64ecc47a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/helpers.py:19: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  return comp1.similarity(comp2)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/helpers.py:19: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  return comp1.similarity(comp2)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:108: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  v2 = A_verbParent.similarity(Q_verbParent)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:110: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  otherVerbSim = [(t.similarity(Q_verbParent) if \\\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:118: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  otherQverbs = [(A_verbParent.similarity(t) if \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/dennyCode_modified.py:23: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim = sentence_nostop.similarity(question_nostop)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    }
   ],
   "source": [
    "error_question,error_answer,error_context = get_dataset(df,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c5b65-9506-43f1-b0e1-0e5d0b83b0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
