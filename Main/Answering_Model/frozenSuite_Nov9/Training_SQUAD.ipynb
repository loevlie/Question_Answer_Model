{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "164a25bf",
   "metadata": {},
   "source": [
    "# Working with SQUAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "429cec3c-cf78-4002-a73d-ceba85cb4d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.1-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 957 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/Denny/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /Users/Denny/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.6.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/Denny/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "683fd285-4612-411c-ae77-3193e1dc2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:854: Loading model from XGBoost < 1.0.0, consider saving it again for improved compatibility\n"
     ]
    }
   ],
   "source": [
    "import NN_Model_Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e793c3f-1385-476e-82a4-5c5eaf5121a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477fbe3-f6eb-4fd8-a990-3f2c3fa1f189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b5ae0f-dd0a-498e-bf17-e2df85c5b842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6303e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Utils import get_features\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from testingHelpers import NBcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529a2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('train-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a877428-c4c3-4716-a668-d9e255541849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_title(df,title_index):\n",
    "    \"\"\"Function to parse the SQUAD data structure for one article and return the full text, Questions and Answers.\n",
    "\n",
    "    Args:\n",
    "        df (dict): SQUAD data set structure\n",
    "        title_index (int): Index number for the article you would like to parse\n",
    "\n",
    "    Returns:\n",
    "        text (str): The full text of the article (paragraphs are separated by \\n)\n",
    "        Questions (list): A list of all of the questions (marked as possible)\n",
    "        Answers (list):  A list of all the answers corresponding to the Question list \n",
    "    \"\"\"\n",
    "\n",
    "    text = '\\n'.join([df['data'][title_index]['paragraphs'][i]['context'] for i in range(len(df['data'][title_index]['paragraphs']))])\n",
    "\n",
    "    Questions = []\n",
    "    Answers = []\n",
    "\n",
    "    for i in range(len(df['data'][title_index]['paragraphs'])):\n",
    "        for j in range(len(df['data'][title_index]['paragraphs'][i]['qas'])):\n",
    "            if df['data'][title_index]['paragraphs'][i]['qas'][j]['is_impossible'] == True:\n",
    "                continue\n",
    "            else:\n",
    "                Questions.append(df['data'][title_index]['paragraphs'][i]['qas'][j]['question'])\n",
    "                Answers.append([x['text'] for x in df['data'][title_index]['paragraphs'][i]['qas'][j]['answers']])\n",
    "    \n",
    "    return text, Questions, Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a33cb31-d300-4fb2-aca2-fe2a4b606640",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_article, Questions, Answers = parse_title(df,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4756ac5e-15c4-4e61-ab15-991d91338fe8",
   "metadata": {},
   "source": [
    "## Saving an Example Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f174da-2150-49b9-be27-bcd186b8ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open text file\n",
    "text_file = open(\"Example_Article/Article_Example.txt\", \"w\")\n",
    "\n",
    "#write string to file\n",
    "text_file.write(text_article)\n",
    "\n",
    "#close file\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208104b6-0bd7-4b45-b88b-0d48f82eeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'Questions':Questions,'Answers':Answers})\n",
    "df2.to_csv('Example_Article/Questions_and_Answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18debe9b-d1f6-48d1-805c-dd45793624f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d6098b-0e37-45d8-ae1b-34b1224ec1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import spacy\n",
    "import QAfeatures\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "\n",
    "\n",
    "def random_index(n, end, start = 0):\n",
    "    return list(range(start, n)) + list(range(n+1, end))\n",
    "\n",
    "def filter_questions_find_len(vecs,Answers):\n",
    "    \"\"\"First figure out if the answer was found in the feature vectors.  Next find and return the answer feature vector and a randomly selected incorrect answer feature vector.\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        vecs (list): list of n feature vectors (from n sentences choosen previously)\n",
    "        Answers (list): list of answers given by SQUAD\n",
    "\n",
    "    Returns:\n",
    "        found_answer (bool): Was the answer found or not?\n",
    "        correct_feature_vector (array): Feaure vector of the correct answer\n",
    "        incorrect_feature_vector (array): Feature vector of the incorrect answer\n",
    "    \"\"\"\n",
    "\n",
    "    # Did we find the correct answer?\n",
    "    check = []\n",
    "    for vec in vecs:\n",
    "        check.append(any(item in Answers for item in [str(i) for i in vec.keys()]))\n",
    "    \n",
    "    if any(check):\n",
    "        break_out_flag = False\n",
    "        for vec in vecs:\n",
    "            for Answer in set(Answers):\n",
    "                vec_list = [str(i) for i in vec.keys()]\n",
    "                if Answer in vec_list:\n",
    "                    correct_index = vec_list.index(Answer)\n",
    "                    correct_feature_vector = list(vec.values())[correct_index]\n",
    "                    # print(\n",
    "                    #incorrect_feature_vectors = [x for i,x in enumerate(list(vec.values())) if i!=correct_index]\n",
    "                    incorrect_feature_vector = list(vec.values())[random.choice(random_index(correct_index,len(list(vec.values()))))]\n",
    "                    count = 1\n",
    "                    while all(incorrect_feature_vector==correct_feature_vector):\n",
    "                        incorrect_feature_vector = list(vec.values())[random.choice(random_index(correct_index,len(list(vec.values()))))]\n",
    "                        count+=1\n",
    "                        if count==10:\n",
    "                            correct_feature_vector = np.array([])\n",
    "                            incorrect_feature_vector= np.array([])\n",
    "                            found_answer = False\n",
    "                            break\n",
    "                    break_out_flag = True\n",
    "                    found_answer = True\n",
    "                    break\n",
    "            if break_out_flag:\n",
    "                break\n",
    "    else:\n",
    "        correct_feature_vector = np.array([])\n",
    "        incorrect_feature_vector = np.array([])\n",
    "        found_answer = False\n",
    "\n",
    "\n",
    "    return found_answer, correct_feature_vector, incorrect_feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc31ec6c-556a-46cd-a8e1-1ca18b15231c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae2e47-80c9-4574-a558-a36677040f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552c01c-0cfc-4223-9d09-4d01479b3f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a459c5dc-380f-40a2-ac80-52ee960b33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def random_index(n, end, start = 0):\n",
    "    return list(range(start, n)) + list(range(n+1, end))\n",
    "\n",
    "def filter_questions(vecs,Answers):\n",
    "    \"\"\"First figure out if the answer was found in the feature vectors.  Next find and return the answer feature vector and a randomly selected incorrect answer feature vector.\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        vecs (list): list of n feature vectors (from n sentences choosen previously)\n",
    "        Answers (list): list of answers given by SQUAD\n",
    "\n",
    "    Returns:\n",
    "        found_answer (bool): Was the answer found or not?\n",
    "        correct_feature_vector (array): Feaure vector of the correct answer\n",
    "        incorrect_feature_vector (array): Feature vector of the incorrect answer\n",
    "    \"\"\"\n",
    "\n",
    "    # Did we find the correct answer?\n",
    "    check = []\n",
    "    for vec in vecs:\n",
    "        check.append(any(item in Answers for item in [str(i) for i in vec.keys()]))\n",
    "    \n",
    "    if any(check):\n",
    "        break_out_flag = False\n",
    "        for vec in vecs:\n",
    "            for Answer in set(Answers):\n",
    "                vec_list = [str(i) for i in vec.keys()]\n",
    "                if Answer in vec_list:\n",
    "                    correct_index = vec_list.index(Answer)\n",
    "                    correct_feature_vector = list(vec.values())[correct_index]\n",
    "                    # print(\n",
    "                    #incorrect_feature_vectors = [x for i,x in enumerate(list(vec.values())) if i!=correct_index]\n",
    "                    incorrect_feature_vector = list(vec.values())[random.choice(random_index(correct_index,len(list(vec.values()))))]\n",
    "                    count = 1\n",
    "                    while all(incorrect_feature_vector==correct_feature_vector):\n",
    "                        incorrect_feature_vector = list(vec.values())[random.choice(random_index(correct_index,len(list(vec.values()))))]\n",
    "                        count+=1\n",
    "                        if count==10:\n",
    "                            correct_feature_vector = np.array([])\n",
    "                            incorrect_feature_vector = np.array([])\n",
    "                            found_answer = False\n",
    "                            break\n",
    "                    break_out_flag = True\n",
    "                    found_answer = True\n",
    "                    break\n",
    "            if break_out_flag:\n",
    "                break\n",
    "    else:\n",
    "        correct_feature_vector = np.array([])\n",
    "        incorrect_feature_vector = np.array([])\n",
    "        found_answer = False\n",
    "\n",
    "\n",
    "    return found_answer, correct_feature_vector, incorrect_feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0731eb-9f54-488f-913c-ed60fdb204a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_len(df,rel_sentences=3,max_len_start=0):\n",
    "    ######## THIS IS THE SECTION THAT TAKES FOREVER ##########\n",
    "    feature_vec = []\n",
    "    output_vec = []\n",
    "    max_len = max_len_start\n",
    "    for j in tqdm(range(len(df['data']))):\n",
    "        for P in df['data'][j]['paragraphs']:\n",
    "            for i, QA in enumerate(P['qas']):\n",
    "                if QA['is_impossible']:\n",
    "                    continue\n",
    "\n",
    "                try: # TODO \n",
    "                    QS = QAfeatures.QuestionSense(QA['question'])\n",
    "                    vecs = get_features(text=nlp(P['context']),question=QS,num_rel_sentences=rel_sentences)\n",
    "                    \n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    found, correct, incorrect = filter_questions(vecs,[x['text'] for x in QA['answers']])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if found:\n",
    "                    all_vectors = []\n",
    "                    for vec in vecs:\n",
    "                        for vector in list(vec.values()):\n",
    "                            all_vectors.append(vector)\n",
    "                    vec_len = len(all_vectors)\n",
    "                    if vec_len > max_len:\n",
    "                        max_len = vec_len\n",
    "                        \n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "379bc603-4161-4b4f-a696-3b6c15e6299c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d181dd09-474c-4a34-8f5a-1e20a6de0ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e901a0e1395a4d16b2e7a85b62a47975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:92: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  v1 = max(candidate.similarity(QS.descriptors),\\\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:103: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  v2 = A_verbParent.similarity(Q_verbParent)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:95: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  v1 = candidate.similarity(QS.descriptors)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:93: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  alternate.similarity(QS.descriptors))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/dennyCode_modified.py:30: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim = sentence_nostop.similarity(question_nostop)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    }
   ],
   "source": [
    "max_len = find_len(df,3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b9361b-5d20-42ef-92d8-b3664856f5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4aa94c-7f8f-41ec-b25e-fb7ed9bf6e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273be654a9e64624aa165283f6c32c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:74: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  v1 = candidate.similarity(QS.descriptors)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:82: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  v2 = A_verbParent.similarity(Q_verbParent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/dennyCode_modified.py:30: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim = sentence_nostop.similarity(question_nostop)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    }
   ],
   "source": [
    "max_len = find_len(df,3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd3ed3-8930-4a1d-9503-14e787df6ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75afe93-0db4-4844-b93b-3ae5ee880814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import spacy\n",
    "import QAfeatures\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def random_index(n, end, start = 0):\n",
    "    return list(range(start, n)) + list(range(n+1, end))\n",
    "\n",
    "def filter_questions(vecs,Answers,max_len=30):\n",
    "    \"\"\"First figure out if the answer was found in the feature vectors.  Next find and return the answer feature vector and a randomly selected incorrect answer feature vector.\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        vecs (list): list of n feature vectors (from n sentences choosen previously)\n",
    "        Answers (list): list of answers given by SQUAD\n",
    "\n",
    "    Returns:\n",
    "        found_answer (bool): Was the answer found or not?\n",
    "        correct_feature_vector (array): Feaure vector of the correct answer\n",
    "        incorrect_feature_vector (array): Feature vector of the incorrect answer\n",
    "    \"\"\"\n",
    "\n",
    "    # Did we find the correct answer?\n",
    "    feat_len = len(list(vecs.values())[0])\n",
    "    PAD = np.ones(feat_len)*-1\n",
    "    check = []\n",
    "    # for vec in vecs:\n",
    "    check.append(any(item in Answers for item in [str(i) for i in vecs.keys()]))\n",
    "    \n",
    "    feature_vectors = []\n",
    "    candidate_list = []\n",
    "    if any(check):\n",
    "        break_out_flag = False\n",
    "        # for vec in vecs:\n",
    "        feature_vectors.extend(list(vecs.values()))\n",
    "        candidate_list.extend([str(i) for i in list(vecs.keys())])\n",
    "        for Answer in set(Answers):\n",
    "            #vec_list = [str(i) for i in vec.keys()]\n",
    "            if Answer in candidate_list:\n",
    "                correct_index = candidate_list.index(Answer)\n",
    "                # print(feature_vectors)\n",
    "                # print(feature_vectors[correct_index])\n",
    "                # print(feature_vectors.count(feature_vectors[correct_index]))\n",
    "                count = 0\n",
    "                for i in feature_vectors:\n",
    "                    if all(i==list(feature_vectors[correct_index])):\n",
    "                        count+=1\n",
    "                \n",
    "                if count > 1: # This would mean there is at least one more feature vector equal to the correct one that is not correct \n",
    "                    feature_vectors = np.array([])\n",
    "                    output_vector = np.array([])\n",
    "                    found_answer = False\n",
    "                    break\n",
    "                else:\n",
    "                    if len(feature_vectors) < max_len: # We must pad!\n",
    "                        padding_array = [PAD for i in range(max_len-len(feature_vectors))]\n",
    "                        feature_vectors.extend(padding_array)\n",
    "                    \n",
    "                    output_vector = np.zeros(len(feature_vectors))\n",
    "                    output_vector[correct_index] = 1 # should still be the same index right?\n",
    "\n",
    "                    indices = np.arange(max_len)\n",
    "\n",
    "                    np.random.shuffle(indices)\n",
    "                    feature_vectors = np.array(feature_vectors)[indices]\n",
    "                    output_vector = np.array(output_vector)[indices]\n",
    "                    break_out_flag = True\n",
    "                    found_answer = True\n",
    "                    break\n",
    "            # if break_out_flag:\n",
    "            #     break\n",
    "    else:\n",
    "        feature_vectors = np.array([])\n",
    "        output_vector = np.array([])\n",
    "        found_answer = False\n",
    "\n",
    "\n",
    "    return found_answer, feature_vectors, output_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset(df,rel_sentences=3):\n",
    "    ######## THIS IS THE SECTION THAT TAKES FOREVER ##########\n",
    "    feature_vec = []\n",
    "    output_vec = []\n",
    "    message = []\n",
    "    error_question = []\n",
    "    # Qtype = []\n",
    "    # Atype = []\n",
    "\n",
    "    for j in tqdm(range(len(df['data']))):\n",
    "        # if j == len(df['data'])-1:\n",
    "        #     return Qtype,Atype\n",
    "        #     break\n",
    "        #print(len(feature_vec))\n",
    "        #text, Questions, Answers = parse_title(df,j)\n",
    "        for P in df['data'][j]['paragraphs']:\n",
    "            for i, QA in enumerate(P['qas']):\n",
    "                if QA['is_impossible']:\n",
    "                    continue\n",
    "                \n",
    "                try: \n",
    "                    QS = QAfeatures.QuestionSense(QA['question'])\n",
    "                except:\n",
    "                    continue\n",
    "                try: # TODO \n",
    "                    vecs = get_features(text=nlp(P['context']),QS=QS,num_rel_sentences=rel_sentences)\n",
    "                except:\n",
    "                    #message.append(att)\n",
    "                    #error_question.append(QA['question'])\n",
    "                    continue\n",
    "                \n",
    "                if vecs == []:\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                \n",
    "                #print(vecs)\n",
    "                all_vectors = []\n",
    "                # for vec in vecs:\n",
    "\n",
    "                for vector in list(vecs.values()):\n",
    "                    all_vectors.append(vector)\n",
    "\n",
    "                vec_len = len(all_vectors)\n",
    "                if vec_len > 30:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    found, all_vecs, out = filter_questions(vecs,[x['text'] for x in QA['answers']])\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                if found:\n",
    "                    \n",
    "                    # qtypei, atypei = NBcount(questionText=QA['question'],answerText=QA['answers'][0]['text'],contextText=P['context'])\n",
    "                    # Qtype.append(qtypei)\n",
    "                    # Atype.append(atypei)\n",
    "                    \n",
    "                    feature_vec.append(all_vecs)\n",
    "                    #print(np.array(feature_vec).shape)\n",
    "                    output_vec.append(out)\n",
    "                    #print(len(np.array(output_vec)))\n",
    "   \n",
    "\n",
    "\n",
    "    ############################################################\n",
    "    a = np.array(feature_vec)\n",
    "    b = np.array(output_vec)\n",
    "\n",
    "    indices = np.arange(len(b))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    feature_vec = a[indices]\n",
    "    output_vec = b[indices]\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(feature_vec, output_vec, test_size=0.20, random_state=42)\n",
    "    return feature_vec,output_vec\n",
    "\n",
    "    # return error_question,message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f17da7b-96bb-4f23-bf3b-7db08e350c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'NoneType' object has no attribute 'children'\"], dtype='<U45')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array([str(m) for m in messages2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dac895a1-58bc-4aa8-ae9a-f3bf394d4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df=pd.DataFrame({'Question':errors2,'Error Message':messages2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9da3a9ef-5109-4688-b283-83565102d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Questions_that_caused_Attribution_Error.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4a161e8-c332-4479-8d70-636a9788c847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c702fbee2b41fbbc342fac706ad934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/helpers.py:19: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  return comp1.similarity(comp2)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/helpers.py:19: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  return comp1.similarity(comp2)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:113: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  v2 = A_verbParent.similarity(Q_verbParent)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:115: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  otherVerbSim = [(t.similarity(Q_verbParent) if \\\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:123: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  otherQverbs = [(A_verbParent.similarity(t) if \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/dennyCode_modified.py:23: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim = sentence_nostop.similarity(question_nostop)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    }
   ],
   "source": [
    "errors2,messages2 = get_dataset(df,rel_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83b4c97f-e36d-4c1f-adb9-b231d1f27601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21015, 105, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ee1176-4dae-46c3-a9ef-0f86c43b3b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22800, 30, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a8bd386-c064-4bd8-91d7-528781077eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_vec, output_vec, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7be397f-c413-4738-960c-adf98c52058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_Unique = np.unique(np.array([i for i in Qtype if isinstance(i,str)]))\n",
    "A_Unique = np.unique(np.array([i for i in Atype if isinstance(i,str)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff997308-bfc7-4d6e-863b-deb0d2041c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AMT_COUNTABLE', 'AMT_UNCOUNTABLE', 'LOCATION', 'PERSON', 'TIME'],\n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_Unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87dbb260-4e6c-4777-b1c5-e6fd1204e382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW',\n",
       "       'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON',\n",
       "       'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART'], dtype='<U11')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_Unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a5b0fc-ba4b-4014-9b7a-8603ba215317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67d8b65b-ad70-47e9-923d-e3475cd5613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55bef3a9-c37e-41e4-97f9-f43a078d1858",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c7eeab4-6ae9-4171-9f78-5e11610fd842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09f71a2b-5f78-4361-9804-93183339c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Q_type in Q_Unique:\n",
    "    for A_type in A_Unique:\n",
    "        for i,j in zip(Qtype,Atype):\n",
    "            if i==Q_type and j == A_type:\n",
    "                counts[Q_type+'-'+A_type]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ee3b73e-75fc-4944-be4d-79d7eeb5907f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7064"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "605d1bed-7376-4cad-9cf9-b0280fe203d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('Type_Counts.pkl', 'wb') as f:\n",
    "    pickle.dump(counts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb99c58-7d2e-443d-a11c-9a51ccf8b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('saved_dictionary.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a86cbae5-c888-4b32-84b8-4e730550a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94439188-1f9a-4e6c-8a5b-33c9739e5d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'TIME': 38,\n",
       "         None: 155,\n",
       "         'PERSON': 50,\n",
       "         'AMT_COUNTABLE': 12,\n",
       "         'LOCATION': 6,\n",
       "         'AMT_UNCOUNTABLE': 2})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Qtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc86efcb-f098-40fc-8ad0-46dba3e76b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'DATE': 42,\n",
       "         None: 58,\n",
       "         'PERSON': 74,\n",
       "         'CARDINAL': 14,\n",
       "         'ORG': 58,\n",
       "         'GPE': 13,\n",
       "         'FAC': 1,\n",
       "         'TIME': 1,\n",
       "         'MONEY': 1,\n",
       "         'EVENT': 1})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Atype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8898fe1-5c9c-4e5b-b4ca-0db858105585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22800, 30, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50b3fcf6-e333-4795-8ba0-d15857bc1034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50a014692b544638c596fba7c532878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/helpers.py:19: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  return comp1.similarity(comp2)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/helpers.py:19: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  return comp1.similarity(comp2)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:108: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  v2 = A_verbParent.similarity(Q_verbParent)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:110: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  otherVerbSim = [(t.similarity(Q_verbParent) if \\\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:118: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  otherQverbs = [(A_verbParent.similarity(t) if \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/dennyCode_modified.py:23: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim = sentence_nostop.similarity(question_nostop)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    }
   ],
   "source": [
    "feature_vec, output_vec = get_dataset(df,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7d4b1-9604-4794-989f-8604392d4553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5efadb5eefd4b948513859a8f50ba29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 105, 8)\n",
      "1\n",
      "(2, 105, 8)\n",
      "2\n",
      "(3, 105, 8)\n",
      "3\n",
      "(4, 105, 8)\n",
      "4\n",
      "(5, 105, 8)\n",
      "5\n",
      "(6, 105, 8)\n",
      "6\n",
      "(7, 105, 8)\n",
      "7\n",
      "(8, 105, 8)\n",
      "8\n",
      "(9, 105, 8)\n",
      "9\n",
      "(10, 105, 8)\n",
      "10\n",
      "(11, 105, 8)\n",
      "11\n",
      "(12, 105, 8)\n",
      "12\n",
      "(13, 105, 8)\n",
      "13\n",
      "(14, 105, 8)\n",
      "14\n",
      "(15, 105, 8)\n",
      "15\n",
      "(16, 105, 8)\n",
      "16\n",
      "(17, 105, 8)\n",
      "17\n",
      "(18, 105, 8)\n",
      "18\n",
      "(19, 105, 8)\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:92: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  v1 = max(candidate.similarity(QS.descriptors),\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 105, 8)\n",
      "20\n",
      "(21, 105, 8)\n",
      "21\n",
      "(22, 105, 8)\n",
      "22\n",
      "(23, 105, 8)\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_dataset(df,rel_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7932351-7f36-44d2-9f23-10328a11b8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b838f6-2db9-4271-aa82-6e2d89d2a8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220e88c-e9da-4090-a00d-79218e602351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e2463-57cc-4161-9123-baa4a6ad4c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b153c2-5e5c-4815-ab9f-eb70c2abfb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "for i, array in enumerate(X_train):\n",
    "    if len(array) != 7:\n",
    "        idxs.append(i)\n",
    "\n",
    "X_train , y_train = np.delete(X_train,idxs),np.delete(y_train,idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a9d376-f20d-4b09-93c2-147ebc50cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "for i, array in enumerate(X_test):\n",
    "    if len(array) != 7:\n",
    "        idxs.append(i)\n",
    "\n",
    "X_test , y_test = np.delete(X_test,idxs),np.delete(y_test,idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f282de-3028-4c2d-a0dd-a2ab3ef8c6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14105268,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1564d7f1-f710-4224-95fb-993c99456916",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.feature_vec = X\n",
    "        self.output_vec = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.output_vec)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.feature_vec[idx])\n",
    "        y = torch.tensor(self.output_vec[idx])\n",
    "        return x , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f54d12c-cec6-4f0e-bea6-37a9f4a75f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a1de38a-97fb-4157-a4a2-159d5bda29e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.2261, 0.7028, 1.0000, 0.0000, 7.0000, 0.0000, 1.0000],\n",
      "       dtype=torch.float64), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "print(train_set.__getitem__(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08989c36-034e-4138-8703-bb60288c6ec6",
   "metadata": {},
   "source": [
    "Initializing the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff2223b7-5007-49bd-92f4-f38f1e501d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=25, shuffle=True, num_workers=1, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701e4c7-ba95-4f5a-93cf-9dbd22d81c16",
   "metadata": {},
   "source": [
    "Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "949931d3-c859-474d-ad6b-1893539d6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self,in_features=7,h1=2048,h2=2048,h3=1024*2,h4=1024,h5=900,h6=900,h7=800,\n",
    "                 h8=800,h9 = 800,h10=800,h11=800,h12=800,h13=800,h14=800,h15=800,out_features=1):\n",
    "        \n",
    "        # How many layers?\n",
    "        # Input layer (# of features) --> hidden layer 1 (number of neurons N) --> h2 (N) --> output (346 of classes)\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=h1,momentum=0.01)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.d2 =  nn.Dropout(0.25)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=h2,momentum=0.01)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=h3,momentum=0.01)\n",
    "        self.d3 = nn.Dropout(0.4)\n",
    "        self.fc4 = nn.Linear(h3,h4)\n",
    "        self.bn4 = nn.BatchNorm1d(num_features=h4,momentum=0.01)\n",
    "        self.d4 = nn.Dropout(0.3)\n",
    "        self.fc5 = nn.Linear(h4,h5)\n",
    "        self.bn5 = nn.BatchNorm1d(num_features=h5,momentum=0.01)\n",
    "        self.d5 = nn.Dropout(0.25)\n",
    "        self.fc6 = nn.Linear(h5,h6)\n",
    "        self.bn6 = nn.BatchNorm1d(num_features=h6,momentum=0.01)\n",
    "        self.d6 = nn.Dropout(0.35)\n",
    "        \n",
    "#         self.fc7 = nn.Linear(h6,h7)\n",
    "#         self.bn7 = nn.BatchNorm1d(num_features=h7,momentum=0.01)\n",
    "#         self.d7 = nn.Dropout(0.4)\n",
    "        \n",
    "#         self.fc8 = nn.Linear(h7,h8)\n",
    "#         self.bn8 = nn.BatchNorm1d(num_features=h8,momentum=0.01)\n",
    "#         self.d8 = nn.Dropout(0.35)\n",
    "        \n",
    "#         self.fc9 = nn.Linear(h8,h9)\n",
    "#         self.bn9 = nn.BatchNorm1d(num_features=h9,momentum=0.01)\n",
    "#         self.d9 = nn.Dropout(0.2)\n",
    "        \n",
    "#         self.fc10 = nn.Linear(h9,h10)\n",
    "#         self.bn10 = nn.BatchNorm1d(num_features=h10,momentum=0.01)\n",
    "#         self.d10 = nn.Dropout(0.25)\n",
    "        \n",
    "#         self.fc11 = nn.Linear(h10,h11)\n",
    "#         self.bn11 = nn.BatchNorm1d(num_features=h11,momentum=0.01)\n",
    "#         self.d11 = nn.Dropout(0.2)\n",
    "\n",
    "#         self.fc12 = nn.Linear(h11,h12)\n",
    "#         self.bn12 = nn.BatchNorm1d(num_features=h12,momentum=0.01)\n",
    "#         self.d12 = nn.Dropout(0.2)\n",
    "\n",
    "#         self.fc13 = nn.Linear(h12,h13)\n",
    "#         self.bn13 = nn.BatchNorm1d(num_features=h13,momentum=0.01)\n",
    "#         self.d13 = nn.Dropout(0.2)\n",
    "\n",
    "#         self.fc14 = nn.Linear(h13,h14)\n",
    "#         self.bn14 = nn.BatchNorm1d(num_features=h14,momentum=0.01)\n",
    "#         self.d14 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc15 = nn.Linear(h6,h15)\n",
    "        self.bn15 = nn.BatchNorm1d(num_features=h15,momentum=0.01)\n",
    "        self.d15 = nn.Dropout(0.2)\n",
    "\n",
    "        self.out = nn.Linear(h15,out_features)\n",
    "  \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.d2(self.fc2(x))))\n",
    "        x = F.relu(self.bn3(self.d3(self.fc3(x))))\n",
    "        x = F.relu(self.bn4(self.d4(self.fc4(x))))\n",
    "        x = F.relu(self.bn5(self.d5(self.fc5(x))))\n",
    "        x = F.relu(self.bn6(self.d6(self.fc6(x))))\n",
    "        # x = F.relu(self.bn7(self.d7(self.fc7(x))))\n",
    "        # x = F.relu(self.bn8(self.d8(self.fc8(x))))\n",
    "        # x = F.relu(self.bn9(self.d9(self.fc9(x))))\n",
    "        # x = F.relu(self.bn10(self.d10(self.fc10(x))))\n",
    "        # x = F.relu(self.bn11(self.d11(self.fc11(x))))\n",
    "        # x = F.relu(self.bn12(self.d12(self.fc12(x))))\n",
    "        # x = F.relu(self.bn13(self.d13(self.fc13(x))))\n",
    "        # x = F.relu(self.bn14(self.d14(self.fc14(x))))\n",
    "        x = F.relu(self.bn15(self.d15(self.fc15(x))))\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be35fcb1-5a88-4df8-a1c4-781ff5852e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a29e8b59-403b-4040-8c71-0c1c070ed795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=7, out_features=2048, bias=True)\n",
       "  (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (d2): Dropout(p=0.25, inplace=False)\n",
       "  (bn2): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d3): Dropout(p=0.4, inplace=False)\n",
       "  (fc4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d4): Dropout(p=0.3, inplace=False)\n",
       "  (fc5): Linear(in_features=1024, out_features=900, bias=True)\n",
       "  (bn5): BatchNorm1d(900, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d5): Dropout(p=0.25, inplace=False)\n",
       "  (fc6): Linear(in_features=900, out_features=900, bias=True)\n",
       "  (bn6): BatchNorm1d(900, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d6): Dropout(p=0.35, inplace=False)\n",
       "  (fc15): Linear(in_features=900, out_features=800, bias=True)\n",
       "  (bn15): BatchNorm1d(800, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d15): Dropout(p=0.2, inplace=False)\n",
       "  (out): Linear(in_features=800, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cpu\")\n",
    "seq_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17cc6401-c5ef-4454-8c2a-d7110efeac91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=7, out_features=2048, bias=True)\n",
       "  (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (d2): Dropout(p=0.25, inplace=False)\n",
       "  (bn2): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d3): Dropout(p=0.4, inplace=False)\n",
       "  (fc4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d4): Dropout(p=0.3, inplace=False)\n",
       "  (fc5): Linear(in_features=1024, out_features=900, bias=True)\n",
       "  (bn5): BatchNorm1d(900, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d5): Dropout(p=0.25, inplace=False)\n",
       "  (fc6): Linear(in_features=900, out_features=900, bias=True)\n",
       "  (bn6): BatchNorm1d(900, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d6): Dropout(p=0.35, inplace=False)\n",
       "  (fc15): Linear(in_features=900, out_features=800, bias=True)\n",
       "  (bn15): BatchNorm1d(800, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d15): Dropout(p=0.2, inplace=False)\n",
       "  (out): Linear(in_features=800, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c75bac2-fa17-4896-bf92-47dc571c930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9947d2be-e55e-4764-bd15-9e14753ef448",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(seq_model.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95779750-68f1-405c-b881-1abc4adf0aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss [], validation loss: []\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 12426) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 12426) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 12426) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# EPOCHS \n",
    "seq_model.train()\n",
    "epochs = 5\n",
    "losses = []\n",
    "loss = []\n",
    "val_error = []\n",
    "validation_losses = []\n",
    "for i in range(epochs):\n",
    "    losses.append(loss)\n",
    "    validation_losses.append(val_error)\n",
    "    seq_model.train()\n",
    "    print(f'Epoch {i}, loss {loss}, validation loss: {val_error}')\n",
    "    for (xi,yi) in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        xi = xi.to(device)\n",
    "        yi = yi.to(device)\n",
    "        output = seq_model(xi)\n",
    "        loss = criterion(torch.squeeze(output),yi)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # if (i+1) % 5 == 0:\n",
    "    #   Testing_Model(seq_model,test_loader,i)\n",
    "    # val_error = validation_error(seq_model,criterion,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8263a414-832b-47b9-b300-f897f89110e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1892"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6536f172-ef79-4619-8290-766799e78a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0.22608298, 0.70279014, 1.        , 0.        , 7.        ,\n",
       "       0.        , 1.        ]),\n",
       "       array([0.75444967, 0.41330665, 1.        , 0.        , 3.        ,\n",
       "       0.        , 2.        ]),\n",
       "       array([0, 0, 1, 0, 3, 0, 1]), ...,\n",
       "       array([0.        , 0.50098819, 1.        , 0.        , 2.        ,\n",
       "       1.        , 1.        ]),\n",
       "       array([0, 0, 1, 0, 8, 1, 1]),\n",
       "       array([0.28018862, 0.45312098, 1.        , 1.        , 8.        ,\n",
       "       0.        , 1.        ])], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b076e085-8818-4c8d-8a5e-9c5ed2a38e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train_full',X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1489187-fd9c-484a-b77a-f42a6bfa1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_train_full',y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8dc2e56-1d93-4fe2-82cd-3d115c4aafbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_test_full',X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71df3fb1-5d07-43b3-bb11-f4b43fe68fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_test_full',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c7cf22-f8b3-49be-bfe2-a65dfaf79304",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('feature_vec',feature_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e6b0437-fddd-4401-aff3-195d4ae113d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('output_vec',output_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d076631e-6738-44e5-9ccc-6182c63f0549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eab545-a418-45ff-8d57-608c40a968e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2c045-8a03-47ac-9c30-28c040d07dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15da16fa-2eb0-4e01-838c-7187409fb422",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('feature_vec.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e5cc2f7-fe5c-479e-85d8-73a42d87b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.load('output_vec.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "635f2fb6-b15d-478f-a2a5-5897b77a420c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21015, 105)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc41e26e-f9a9-4dc7-b975-352ab25073e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21015, 105, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34cbb822-243c-42f2-a07f-f14aef81dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, outputs, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6effe6e4-231b-45de-8756-fcf984475f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16812, 105, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eac14885-877c-40bd-be0b-d78f8e93c21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16812, 105)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18c65fbd-e49f-4fb6-81c5-40c41ce50d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('X_train_full.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4814bfa3-7429-4716-8f9d-4febd3228aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16812, 105, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa201f-43fd-475d-a23f-aeb1f66e781a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
