{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "164a25bf",
   "metadata": {},
   "source": [
    "# Working with SQUAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6303e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Utils import get_features\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529a2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('train-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a877428-c4c3-4716-a668-d9e255541849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_title(df,title_index):\n",
    "    \"\"\"Function to parse the SQUAD data structure for one article and return the full text, Questions and Answers.\n",
    "\n",
    "    Args:\n",
    "        df (dict): SQUAD data set structure\n",
    "        title_index (int): Index number for the article you would like to parse\n",
    "\n",
    "    Returns:\n",
    "        text (str): The full text of the article (paragraphs are separated by \\n)\n",
    "        Questions (list): A list of all of the questions (marked as possible)\n",
    "        Answers (list):  A list of all the answers corresponding to the Question list \n",
    "    \"\"\"\n",
    "\n",
    "    text = '\\n'.join([df['data'][title_index]['paragraphs'][i]['context'] for i in range(len(df['data'][title_index]['paragraphs']))])\n",
    "\n",
    "    Questions = []\n",
    "    Answers = []\n",
    "\n",
    "    for i in range(len(df['data'][title_index]['paragraphs'])):\n",
    "        for j in range(len(df['data'][title_index]['paragraphs'][i]['qas'])):\n",
    "            if df['data'][title_index]['paragraphs'][i]['qas'][j]['is_impossible'] == True:\n",
    "                continue\n",
    "            else:\n",
    "                Questions.append(df['data'][title_index]['paragraphs'][i]['qas'][j]['question'])\n",
    "                Answers.append([x['text'] for x in df['data'][title_index]['paragraphs'][i]['qas'][j]['answers']])\n",
    "    \n",
    "    return text, Questions, Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc7202-61c6-43f9-9d1e-6cf2320d01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = get_features(text=df['data'][0]['paragraphs'][0]['context'],question=df['data'][0]['paragraphs'][0]['qas'][0]['question'],num_rel_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705de81d-6ce9-499c-a49e-9764cd5a8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fec4d3-52b3-4eff-ac96-0eb5e4cc1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors = []\n",
    "\n",
    "for vec in vecs:\n",
    "    for vector in list(vec.values()):\n",
    "        all_vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577521b7-861d-4426-9896-dc6c5aabbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05914202-7345-435b-a0a5-65008d13dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in tqdm(range(len(df['data']))):\n",
    "    #text, Questions, Answers = parse_title(df,j)\n",
    "    for P in df['data'][j]['paragraphs']:\n",
    "        for i, QA in enumerate(P['qas']):\n",
    "            if QA['is_impossible']:\n",
    "                continue\n",
    "\n",
    "            try: # TODO \n",
    "                vecs = get_features(text=P['context'],question=QA['question'],num_rel_sentences=rel_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d6098b-0e37-45d8-ae1b-34b1224ec1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import spacy\n",
    "import QAfeatures\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "\n",
    "\n",
    "def random_index(n, end, start = 0):\n",
    "    return list(range(start, n)) + list(range(n+1, end))\n",
    "\n",
    "def filter_questions_find_len(vecs,Answers):\n",
    "    \"\"\"First figure out if the answer was found in the feature vectors.  Next find and return the answer feature vector and a randomly selected incorrect answer feature vector.\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        vecs (list): list of n feature vectors (from n sentences choosen previously)\n",
    "        Answers (list): list of answers given by SQUAD\n",
    "\n",
    "    Returns:\n",
    "        found_answer (bool): Was the answer found or not?\n",
    "        correct_feature_vector (array): Feaure vector of the correct answer\n",
    "        incorrect_feature_vector (array): Feature vector of the incorrect answer\n",
    "    \"\"\"\n",
    "\n",
    "    # Did we find the correct answer?\n",
    "    check = []\n",
    "    for vec in vecs:\n",
    "        check.append(any(item in Answers for item in [str(i) for i in vec.keys()]))\n",
    "    \n",
    "    if any(check):\n",
    "        break_out_flag = False\n",
    "        for vec in vecs:\n",
    "            for Answer in set(Answers):\n",
    "                vec_list = [str(i) for i in vec.keys()]\n",
    "                if Answer in vec_list:\n",
    "                    correct_index = vec_list.index(Answer)\n",
    "                    correct_feature_vector = list(vec.values())[correct_index]\n",
    "                    # print(\n",
    "                    #incorrect_feature_vectors = [x for i,x in enumerate(list(vec.values())) if i!=correct_index]\n",
    "                    incorrect_feature_vector = list(vec.values())[random.choice(random_index(correct_index,len(list(vec.values()))))]\n",
    "                    count = 1\n",
    "                    while all(incorrect_feature_vector==correct_feature_vector):\n",
    "                        incorrect_feature_vector = list(vec.values())[random.choice(random_index(correct_index,len(list(vec.values()))))]\n",
    "                        count+=1\n",
    "                        if count==10:\n",
    "                            correct_feature_vector = np.array([])\n",
    "                            incorrect_feature_vector= np.array([])\n",
    "                            found_answer = False\n",
    "                            break\n",
    "                    break_out_flag = True\n",
    "                    found_answer = True\n",
    "                    break\n",
    "            if break_out_flag:\n",
    "                break\n",
    "    else:\n",
    "        correct_feature_vector = np.array([])\n",
    "        incorrect_feature_vector = np.array([])\n",
    "        found_answer = False\n",
    "\n",
    "\n",
    "    return found_answer, correct_feature_vector, incorrect_feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc31ec6c-556a-46cd-a8e1-1ca18b15231c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae2e47-80c9-4574-a558-a36677040f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552c01c-0cfc-4223-9d09-4d01479b3f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a459c5dc-380f-40a2-ac80-52ee960b33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def random_index(n, end, start = 0):\n",
    "    return list(range(start, n)) + list(range(n+1, end))\n",
    "\n",
    "def filter_questions(vecs,Answers):\n",
    "    \"\"\"First figure out if the answer was found in the feature vectors.  Next find and return the answer feature vector and a randomly selected incorrect answer feature vector.\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        vecs (list): list of n feature vectors (from n sentences choosen previously)\n",
    "        Answers (list): list of answers given by SQUAD\n",
    "\n",
    "    Returns:\n",
    "        found_answer (bool): Was the answer found or not?\n",
    "        correct_feature_vector (array): Feaure vector of the correct answer\n",
    "        incorrect_feature_vector (array): Feature vector of the incorrect answer\n",
    "    \"\"\"\n",
    "\n",
    "    # Did we find the correct answer?\n",
    "    check = []\n",
    "    for vec in vecs:\n",
    "        check.append(any(item in Answers for item in [str(i) for i in vec.keys()]))\n",
    "    \n",
    "    if any(check):\n",
    "        break_out_flag = False\n",
    "        for vec in vecs:\n",
    "            for Answer in set(Answers):\n",
    "                vec_list = [str(i) for i in vec.keys()]\n",
    "                if Answer in vec_list:\n",
    "                    correct_index = vec_list.index(Answer)\n",
    "                    correct_feature_vector = list(vec.values())[correct_index]\n",
    "                    # print(\n",
    "                    #incorrect_feature_vectors = [x for i,x in enumerate(list(vec.values())) if i!=correct_index]\n",
    "                    incorrect_feature_vector = list(vec.values())[random.choice(random_index(correct_index,len(list(vec.values()))))]\n",
    "                    count = 1\n",
    "                    while all(incorrect_feature_vector==correct_feature_vector):\n",
    "                        incorrect_feature_vector = list(vec.values())[random.choice(random_index(correct_index,len(list(vec.values()))))]\n",
    "                        count+=1\n",
    "                        if count==10:\n",
    "                            correct_feature_vector = np.array([])\n",
    "                            incorrect_feature_vector = np.array([])\n",
    "                            found_answer = False\n",
    "                            break\n",
    "                    break_out_flag = True\n",
    "                    found_answer = True\n",
    "                    break\n",
    "            if break_out_flag:\n",
    "                break\n",
    "    else:\n",
    "        correct_feature_vector = np.array([])\n",
    "        incorrect_feature_vector = np.array([])\n",
    "        found_answer = False\n",
    "\n",
    "\n",
    "    return found_answer, correct_feature_vector, incorrect_feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0731eb-9f54-488f-913c-ed60fdb204a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_len(df,rel_sentences=3,max_len_start=0):\n",
    "    ######## THIS IS THE SECTION THAT TAKES FOREVER ##########\n",
    "    feature_vec = []\n",
    "    output_vec = []\n",
    "    max_len = max_len_start\n",
    "    for j in tqdm(range(len(df['data']))):\n",
    "        #text, Questions, Answers = parse_title(df,j)\n",
    "        for P in df['data'][j]['paragraphs']:\n",
    "            for i, QA in enumerate(P['qas']):\n",
    "                if QA['is_impossible']:\n",
    "                    continue\n",
    "\n",
    "                #try: # TODO \n",
    "                QS = QAfeatures.QuestionSense(QA['question'])\n",
    "                vecs = get_features(text=nlp(P['context']),question=QS,num_rel_sentences=rel_sentences)\n",
    "                    \n",
    "                # except:\n",
    "                #     continue\n",
    "\n",
    "                try:\n",
    "                    found, correct, incorrect = filter_questions(vecs,[x['text'] for x in QA['answers']])\n",
    "                except:\n",
    "                    continue\n",
    "                #print('True')\n",
    "                if found:\n",
    "                    print('found')\n",
    "                    all_vectors = []\n",
    "                    for vec in vecs:\n",
    "                        for vector in list(vec.values()):\n",
    "                            all_vectors.append(vector)\n",
    "                            \n",
    "                    vec_len = len(all_vectors)\n",
    "                    #print(vec_len)\n",
    "                    if vec_len > 50:\n",
    "                        print(vecs)\n",
    "                        print()\n",
    "                        print(QA['question'])\n",
    "                        print()\n",
    "                        print(P['context'])\n",
    "                        print()\n",
    "                        break\n",
    "                    if vec_len > max_len:\n",
    "                        max_len = vec_len\n",
    "                        \n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d181dd09-474c-4a34-8f5a-1e20a6de0ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e125552d306648199e51cb255c6acc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'QuestionSense' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b9309ce33bae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-87f79170f1a3>\u001b[0m in \u001b[0;36mfind_len\u001b[0;34m(df, rel_sentences, max_len_start)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;31m#try: # TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mQS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQAfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQuestionSense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_rel_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;31m# except:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(text, question, num_rel_sentences)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;31m# 'What disease was Messi diagnosed with?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0msentenceDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdennyCode_modified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_similar_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawText\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_rel_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# num_rel_sentences = 3 --> This is basically a hyper-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m#print('\\n'.join((sentenceDict[i].text.strip()+ ' -- score ' + str(i)) for i in sentenceDict))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/dennyCode_modified.py\u001b[0m in \u001b[0;36mfind_similar_sentences\u001b[0;34m(raw_text, question, length)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Break the text into sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mquestion_nostop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'QuestionSense' object is not iterable"
     ]
    }
   ],
   "source": [
    "max_len = find_len(df,3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b9361b-5d20-42ef-92d8-b3664856f5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4aa94c-7f8f-41ec-b25e-fb7ed9bf6e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273be654a9e64624aa165283f6c32c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:74: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  v1 = candidate.similarity(QS.descriptors)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:82: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  v2 = A_verbParent.similarity(Q_verbParent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/dennyCode_modified.py:30: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim = sentence_nostop.similarity(question_nostop)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    }
   ],
   "source": [
    "max_len = find_len(df,3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd3ed3-8930-4a1d-9503-14e787df6ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c75afe93-0db4-4844-b93b-3ae5ee880814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df,rel_sentences=3):\n",
    "    ######## THIS IS THE SECTION THAT TAKES FOREVER ##########\n",
    "    feature_vec = []\n",
    "    output_vec = []\n",
    "\n",
    "    for j in tqdm(range(len(df['data']))):\n",
    "        #text, Questions, Answers = parse_title(df,j)\n",
    "        for P in df['data'][j]['paragraphs']:\n",
    "            for i, QA in enumerate(P['qas']):\n",
    "                if QA['is_impossible']:\n",
    "                    continue\n",
    "\n",
    "                try: # TODO \n",
    "                    vecs = get_features(text=P['context'],question=QA['question'],num_rel_sentences=rel_sentences)\n",
    "                except:\n",
    "                    continue\n",
    "                # print(vecs)\n",
    "                # print()\n",
    "                # print(QA['answers'])\n",
    "                try:\n",
    "                    found, correct, incorrect = filter_questions(vecs,[x['text'] for x in QA['answers']])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if found:\n",
    "                    feature_vec.append(np.concatenate((correct,incorrect),axis=1))\n",
    "                    output_vec.append(np.array([1,0]))\n",
    "\n",
    "                    # feature_vec.append(incorrect)\n",
    "                    # output_vec.append(0)\n",
    "\n",
    "    ############################################################\n",
    "    a = np.array(feature_vec)\n",
    "    b = np.array(output_vec)\n",
    "\n",
    "    indices = np.arange(a.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    feature_vec = a[indices]\n",
    "    output_vec = b[indices]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_vec, output_vec, test_size=0.20, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7d4b1-9604-4794-989f-8604392d4553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2902f85c9e841ab9ba04d35a1ad29cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:69: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  v1 = candidate.similarity(QS.descriptors)\n",
      "/Users/Denny/Desktop/Natural Language Processing/Question_Answer_Model/Main/Answering_Model/frozenSuite_Nov9/Utils.py:77: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  v2 = A_verbParent.similarity(Q_verbParent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n",
      "Could not resolve this question as a binary comparison\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_dataset(df,rel_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b153c2-5e5c-4815-ab9f-eb70c2abfb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "for i, array in enumerate(X_train):\n",
    "    if len(array) != 7:\n",
    "        idxs.append(i)\n",
    "\n",
    "X_train , y_train = np.delete(X_train,idxs),np.delete(y_train,idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9a9d376-f20d-4b09-93c2-147ebc50cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "for i, array in enumerate(X_test):\n",
    "    if len(array) != 7:\n",
    "        idxs.append(i)\n",
    "\n",
    "X_test , y_test = np.delete(X_test,idxs),np.delete(y_test,idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1564d7f1-f710-4224-95fb-993c99456916",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.feature_vec = X\n",
    "        self.output_vec = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.output_vec)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.feature_vec[idx])\n",
    "        y = torch.tensor(self.output_vec[idx])\n",
    "        return x , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f54d12c-cec6-4f0e-bea6-37a9f4a75f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a1de38a-97fb-4157-a4a2-159d5bda29e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.2261, 0.7028, 1.0000, 0.0000, 7.0000, 0.0000, 1.0000],\n",
      "       dtype=torch.float64), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "print(train_set.__getitem__(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08989c36-034e-4138-8703-bb60288c6ec6",
   "metadata": {},
   "source": [
    "Initializing the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff2223b7-5007-49bd-92f4-f38f1e501d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=25, shuffle=True, num_workers=1, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701e4c7-ba95-4f5a-93cf-9dbd22d81c16",
   "metadata": {},
   "source": [
    "Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "949931d3-c859-474d-ad6b-1893539d6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self,in_features=7,h1=2048,h2=2048,h3=1024*2,h4=1024,h5=900,h6=900,h7=800,\n",
    "                 h8=800,h9 = 800,h10=800,h11=800,h12=800,h13=800,h14=800,h15=800,out_features=1):\n",
    "        \n",
    "        # How many layers?\n",
    "        # Input layer (# of features) --> hidden layer 1 (number of neurons N) --> h2 (N) --> output (346 of classes)\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=h1,momentum=0.01)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.d2 =  nn.Dropout(0.25)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=h2,momentum=0.01)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=h3,momentum=0.01)\n",
    "        self.d3 = nn.Dropout(0.4)\n",
    "        self.fc4 = nn.Linear(h3,h4)\n",
    "        self.bn4 = nn.BatchNorm1d(num_features=h4,momentum=0.01)\n",
    "        self.d4 = nn.Dropout(0.3)\n",
    "        self.fc5 = nn.Linear(h4,h5)\n",
    "        self.bn5 = nn.BatchNorm1d(num_features=h5,momentum=0.01)\n",
    "        self.d5 = nn.Dropout(0.25)\n",
    "        self.fc6 = nn.Linear(h5,h6)\n",
    "        self.bn6 = nn.BatchNorm1d(num_features=h6,momentum=0.01)\n",
    "        self.d6 = nn.Dropout(0.35)\n",
    "        \n",
    "#         self.fc7 = nn.Linear(h6,h7)\n",
    "#         self.bn7 = nn.BatchNorm1d(num_features=h7,momentum=0.01)\n",
    "#         self.d7 = nn.Dropout(0.4)\n",
    "        \n",
    "#         self.fc8 = nn.Linear(h7,h8)\n",
    "#         self.bn8 = nn.BatchNorm1d(num_features=h8,momentum=0.01)\n",
    "#         self.d8 = nn.Dropout(0.35)\n",
    "        \n",
    "#         self.fc9 = nn.Linear(h8,h9)\n",
    "#         self.bn9 = nn.BatchNorm1d(num_features=h9,momentum=0.01)\n",
    "#         self.d9 = nn.Dropout(0.2)\n",
    "        \n",
    "#         self.fc10 = nn.Linear(h9,h10)\n",
    "#         self.bn10 = nn.BatchNorm1d(num_features=h10,momentum=0.01)\n",
    "#         self.d10 = nn.Dropout(0.25)\n",
    "        \n",
    "#         self.fc11 = nn.Linear(h10,h11)\n",
    "#         self.bn11 = nn.BatchNorm1d(num_features=h11,momentum=0.01)\n",
    "#         self.d11 = nn.Dropout(0.2)\n",
    "\n",
    "#         self.fc12 = nn.Linear(h11,h12)\n",
    "#         self.bn12 = nn.BatchNorm1d(num_features=h12,momentum=0.01)\n",
    "#         self.d12 = nn.Dropout(0.2)\n",
    "\n",
    "#         self.fc13 = nn.Linear(h12,h13)\n",
    "#         self.bn13 = nn.BatchNorm1d(num_features=h13,momentum=0.01)\n",
    "#         self.d13 = nn.Dropout(0.2)\n",
    "\n",
    "#         self.fc14 = nn.Linear(h13,h14)\n",
    "#         self.bn14 = nn.BatchNorm1d(num_features=h14,momentum=0.01)\n",
    "#         self.d14 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc15 = nn.Linear(h6,h15)\n",
    "        self.bn15 = nn.BatchNorm1d(num_features=h15,momentum=0.01)\n",
    "        self.d15 = nn.Dropout(0.2)\n",
    "\n",
    "        self.out = nn.Linear(h15,out_features)\n",
    "  \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.d2(self.fc2(x))))\n",
    "        x = F.relu(self.bn3(self.d3(self.fc3(x))))\n",
    "        x = F.relu(self.bn4(self.d4(self.fc4(x))))\n",
    "        x = F.relu(self.bn5(self.d5(self.fc5(x))))\n",
    "        x = F.relu(self.bn6(self.d6(self.fc6(x))))\n",
    "        # x = F.relu(self.bn7(self.d7(self.fc7(x))))\n",
    "        # x = F.relu(self.bn8(self.d8(self.fc8(x))))\n",
    "        # x = F.relu(self.bn9(self.d9(self.fc9(x))))\n",
    "        # x = F.relu(self.bn10(self.d10(self.fc10(x))))\n",
    "        # x = F.relu(self.bn11(self.d11(self.fc11(x))))\n",
    "        # x = F.relu(self.bn12(self.d12(self.fc12(x))))\n",
    "        # x = F.relu(self.bn13(self.d13(self.fc13(x))))\n",
    "        # x = F.relu(self.bn14(self.d14(self.fc14(x))))\n",
    "        x = F.relu(self.bn15(self.d15(self.fc15(x))))\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be35fcb1-5a88-4df8-a1c4-781ff5852e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a29e8b59-403b-4040-8c71-0c1c070ed795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=7, out_features=2048, bias=True)\n",
       "  (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (d2): Dropout(p=0.25, inplace=False)\n",
       "  (bn2): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d3): Dropout(p=0.4, inplace=False)\n",
       "  (fc4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d4): Dropout(p=0.3, inplace=False)\n",
       "  (fc5): Linear(in_features=1024, out_features=900, bias=True)\n",
       "  (bn5): BatchNorm1d(900, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d5): Dropout(p=0.25, inplace=False)\n",
       "  (fc6): Linear(in_features=900, out_features=900, bias=True)\n",
       "  (bn6): BatchNorm1d(900, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d6): Dropout(p=0.35, inplace=False)\n",
       "  (fc15): Linear(in_features=900, out_features=800, bias=True)\n",
       "  (bn15): BatchNorm1d(800, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d15): Dropout(p=0.2, inplace=False)\n",
       "  (out): Linear(in_features=800, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cpu\")\n",
    "seq_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17cc6401-c5ef-4454-8c2a-d7110efeac91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=7, out_features=2048, bias=True)\n",
       "  (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (d2): Dropout(p=0.25, inplace=False)\n",
       "  (bn2): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d3): Dropout(p=0.4, inplace=False)\n",
       "  (fc4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d4): Dropout(p=0.3, inplace=False)\n",
       "  (fc5): Linear(in_features=1024, out_features=900, bias=True)\n",
       "  (bn5): BatchNorm1d(900, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d5): Dropout(p=0.25, inplace=False)\n",
       "  (fc6): Linear(in_features=900, out_features=900, bias=True)\n",
       "  (bn6): BatchNorm1d(900, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d6): Dropout(p=0.35, inplace=False)\n",
       "  (fc15): Linear(in_features=900, out_features=800, bias=True)\n",
       "  (bn15): BatchNorm1d(800, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (d15): Dropout(p=0.2, inplace=False)\n",
       "  (out): Linear(in_features=800, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c75bac2-fa17-4896-bf92-47dc571c930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9947d2be-e55e-4764-bd15-9e14753ef448",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(seq_model.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95779750-68f1-405c-b881-1abc4adf0aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss [], validation loss: []\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 12426) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 12426) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 12426) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# EPOCHS \n",
    "seq_model.train()\n",
    "epochs = 5\n",
    "losses = []\n",
    "loss = []\n",
    "val_error = []\n",
    "validation_losses = []\n",
    "for i in range(epochs):\n",
    "    losses.append(loss)\n",
    "    validation_losses.append(val_error)\n",
    "    seq_model.train()\n",
    "    print(f'Epoch {i}, loss {loss}, validation loss: {val_error}')\n",
    "    for (xi,yi) in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        xi = xi.to(device)\n",
    "        yi = yi.to(device)\n",
    "        output = seq_model(xi)\n",
    "        loss = criterion(torch.squeeze(output),yi)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # if (i+1) % 5 == 0:\n",
    "    #   Testing_Model(seq_model,test_loader,i)\n",
    "    # val_error = validation_error(seq_model,criterion,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8263a414-832b-47b9-b300-f897f89110e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1892"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6536f172-ef79-4619-8290-766799e78a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0.22608298, 0.70279014, 1.        , 0.        , 7.        ,\n",
       "       0.        , 1.        ]),\n",
       "       array([0.75444967, 0.41330665, 1.        , 0.        , 3.        ,\n",
       "       0.        , 2.        ]),\n",
       "       array([0, 0, 1, 0, 3, 0, 1]), ...,\n",
       "       array([0.        , 0.50098819, 1.        , 0.        , 2.        ,\n",
       "       1.        , 1.        ]),\n",
       "       array([0, 0, 1, 0, 8, 1, 1]),\n",
       "       array([0.28018862, 0.45312098, 1.        , 1.        , 8.        ,\n",
       "       0.        , 1.        ])], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b076e085-8818-4c8d-8a5e-9c5ed2a38e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train_full',X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1489187-fd9c-484a-b77a-f42a6bfa1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_train_full',y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8dc2e56-1d93-4fe2-82cd-3d115c4aafbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_test_full',X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71df3fb1-5d07-43b3-bb11-f4b43fe68fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_test_full',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d076631e-6738-44e5-9ccc-6182c63f0549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
